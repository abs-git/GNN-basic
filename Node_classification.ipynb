{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcYiRSQ6RmD2546qSy+XrB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abs-git/GNN-basic/blob/main/Node_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMqOJbgUouky",
        "outputId": "2da61d43-1172-476a-effd-ae10f8143eaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric"
      ],
      "metadata": {
        "id": "aPKIRbsVvmjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WikiCS Dataset\n",
        "\n",
        "> https://arxiv.org/pdf/2007.02901.pdf\n",
        "\n"
      ],
      "metadata": {
        "id": "Fjs3C-mj-9S4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WikiCS\n",
        "# Using wikics dataset\n",
        "\n",
        "print('Number of Graph : {}'.format(len(wikics_dataset)))                            # 그래프의 수 \n",
        "print('Number of Class per graph : {}'.format(wikics_dataset.num_classes))           # 그래프 내의 클래스 수\n",
        "print('Number of feature per each node : {}'.format(wikics_dataset.num_node_features))    # 그래프 내의 노드 특징 수\n",
        "print()\n",
        "\n",
        "data = wikics_dataset[0]\n",
        "\n",
        "print(data)\n",
        "print('Number of nodes : {}'.format(data.num_nodes))\n",
        "print('Number of edges : {}'.format(data.num_edges))\n",
        "print()\n",
        "\n",
        "print('Is it undiectred graph? : {}'.format(data.is_undirected()))                 # 방향성 그래프 or 비방향성 그래프\n",
        "\n",
        "print(data.edge_index.shape)                # 그래프의 연결성 : [2, num_edges] / source node -> target node\n",
        "print(data.x.shape)                         # 노드 특징 행렬 : [num_nodes, num_node_features]\n",
        "print(data.edge_attr)                       # 엣지 특징 행렬 : 존재할 경우 [num_edges, num_edge_features] \n",
        "print(data.y)                               # target 값 : 그래프 레벨 (num_nodes, *), 노드 레벨 (1, *)\n",
        "print(data.y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMDWEtlYWfjm",
        "outputId": "1c4aadcc-5f4f-460c-83a5-ae3bd4e388f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Graph : 1\n",
            "Number of Class per graph : 10\n",
            "Number of feature per node : 300\n",
            "\n",
            "Data(x=[11701, 300], edge_index=[2, 431726], y=[11701], train_mask=[11701, 20], val_mask=[11701, 20], test_mask=[11701], stopping_mask=[11701, 20])\n",
            "Number of nodes : 11701\n",
            "Number of edges : 431726\n",
            "\n",
            "Is it undiectred graph? : True\n",
            "torch.Size([2, 431726])\n",
            "torch.Size([11701, 300])\n",
            "None\n",
            "tensor([7, 2, 2,  ..., 2, 5, 7])\n",
            "torch.Size([11701])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create GCN model\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, GATConv, Linear\n",
        "\n",
        "\n",
        "class GCN(nn.Module):\n",
        "  def __init__(self, hidden_channels, nFeatures, nClasses, dropout_rate):\n",
        "    super(GCN, self).__init__()\n",
        "    \n",
        "    self.conv1 = GCNConv(nFeatures, hidden_channels)\n",
        "    self.conv2 = GCNConv(hidden_channels, nClasses)\n",
        "\n",
        "    self.drop_rate = dropout_rate\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    x = self.conv1(x, edge_index)\n",
        "    x = x.relu()\n",
        "    x = F.dropout(x, self.drop_rate)\n",
        "\n",
        "    x = self.conv2(x, edge_index)\n",
        "\n",
        "    return F.softmax(x, dim = 1)\n",
        "\n",
        "\n",
        "class GAT(nn.Module):\n",
        "  def __init__(self, hidden_channels, nFeatures, nClasses, dropout_rate, attention_heads = 4):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = GATConv(nFeatures, hidden_channels, heads = attention_heads)\n",
        "    self.conv2 = GATConv(hidden_channels * attention_heads, nClasses, heads = 1)\n",
        "    self.out = Linear(hidden_channels, nClasses)\n",
        "\n",
        "    self.drop_rate = dropout_rate\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "\n",
        "    x = self.conv1(x, edge_index)\n",
        "    x = x.relu()\n",
        "    x = F.dropout(x, self.drop_rate)\n",
        "\n",
        "    x = self.conv2(x, edge_index)\n",
        "\n",
        "    return F.softmax(x, dim = 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "mghVS0L1XJ3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning utils\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import time\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def trainer(data, model, optimizer, criterion, i_spilts):\n",
        "  X = data.x\n",
        "  edge_index = data.edge_index  \n",
        "  target = data.y\n",
        "\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  outputs = model(X, edge_index)                    # Use all data as input, because all nodes have node features\n",
        "  \n",
        "  loss = criterion(outputs[data['train_mask'][:,i_spilts]],   \n",
        "                   target[data['train_mask'][:,i_spilts]])    # Only use nodes with labels available for loss calculation\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  return loss\n",
        "\n",
        "\n",
        "def tester(data, model, index, nClasses):\n",
        "  X = data.x\n",
        "  edge_index = data.edge_index\n",
        "  target = data.y\n",
        "  \n",
        "  model.eval()\n",
        "\n",
        "  outputs = model(X, edge_index)[index]\n",
        "\n",
        "  # calculate AUC\n",
        "  y_true = target.cpu().detach().numpy()[index]\n",
        "  y_mat = np.zeros(shape = (y_true.shape[0], nClasses))\n",
        "\n",
        "  for i in range(y_true.shape[0]):\n",
        "    y_mat[i, y_true[i]] = 1\n",
        "  \n",
        "  auc = roc_auc_score(y_mat, outputs.cpu().detach().numpy())\n",
        "  \n",
        "  # calculate Accuracy\n",
        "  pred = outputs.argmax(dim = 1)\n",
        "  correct = int((pred == target[index]).sum())\n",
        "\n",
        "  accuracy = correct / pred.shape[0]\n",
        "\n",
        "  scores = [auc, accuracy]\n",
        "\n",
        "  return scores\n",
        "\n",
        "\n",
        "def experiment(data, model, optimizer, criterion, nClasses, EPOCHS, i_splits):\n",
        "\n",
        "  losses = []\n",
        "  scores = defaultdict(list)\n",
        "\n",
        "  for epoch in range(1, EPOCHS):\n",
        "\n",
        "    loss = trainer(data, GCN_model, GCN_optimizer, GCN_criterion, i_splits)\n",
        "    \n",
        "    train_score = tester(data, GCN_model, data['train_mask'][:,i_splits], nClasses)\n",
        "    val_score = tester(data, GCN_model, data['val_mask'][:,i_splits], nClasses)\n",
        "    test_score = tester(data, GCN_model, data['test_mask'], nClasses)\n",
        "\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    scores['train_auc'].append(train_score[0])\n",
        "    scores['val_auc'].append(val_score[0])\n",
        "    scores['test_auc'].append(test_score[0])\n",
        "\n",
        "    scores['train_accuracy'].append(train_score[1])\n",
        "    scores['val_accuracy'].append(val_score[1])\n",
        "    scores['test_accuracy'].append(test_score[1])\n",
        "\n",
        "    if epoch % 10 == 0 :\n",
        "      print('epoch : {}, train loss : {}'.format(epoch, loss))\n",
        "\n",
        "\n",
        "  return losses, scores\n",
        "\n"
      ],
      "metadata": {
        "id": "0x0EVJurkIAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a GCN model\n",
        "\n",
        "nFeatures = wikics_dataset.num_features\n",
        "nClasses = wikics_dataset.num_classes\n",
        "\n",
        "GCN_model = GCN(hidden_channels = 200, nFeatures = nFeatures, nClasses = nClasses, dropout_rate = 0.3)\n",
        "\n",
        "GCN_optimizer = torch.optim.Adam(GCN_model.parameters(), lr = 0.001)\n",
        "GCN_criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "GCN_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_F6wBuxhkt7",
        "outputId": "47c64f4e-42bc-4250-f93c-dc5bb0e6a83e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GCN(\n",
              "  (conv1): GCNConv(300, 200)\n",
              "  (conv2): GCNConv(200, 10)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "\n",
        "EPOCHS = 100\n",
        "i_splits = 4\n",
        "\n",
        "GCN_losses, GCN_scores = experiment(data, GCN_model, GCN_optimizer, GCN_criterion, nClasses, EPOCHS, i_splits)\n"
      ],
      "metadata": {
        "id": "UzGkQIvo_Z5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(2,2, figsize = (16,16))\n",
        "\n",
        "# AUC\n",
        "axes[0][0].plot(GCN_scores['train_auc'], c = 'r', linestyle = 'solid', linewidth = 3)\n",
        "axes[0][0].plot(GCN_scores['val_auc'], c = 'b', linestyle = 'solid', linewidth = 3)\n",
        "axes[0][0].plot(GCN_scores['test_auc'], c = 'g', linestyle = 'solid', linewidth = 3)\n",
        "\n",
        "axes[0][0].set_ylim(0,1)\n",
        "\n",
        "axes[0][0].set_title(\"AUC\")\n",
        "axes[0][0].set_xlabel('Epoch', fontsize = 15)\n",
        "axes[0][0].set_ylabel('Score', fontsize = 15)\n",
        "\n",
        "axes[0][0].tick_params(labelsize = 15)\n",
        "axes[0][0].grid()\n",
        "\n",
        "axes[0][0].legend(['Train AUC', 'Val AUC', 'Test AUC'], fontsize = 15)\n",
        "\n",
        "\n",
        "# Accuracy\n",
        "axes[0][1].plot(GCN_scores['train_accuracy'], c = 'r', linestyle = 'solid', linewidth = 3)\n",
        "axes[0][1].plot(GCN_scores['val_accuracy'], c = 'b', linestyle = 'solid', linewidth = 3)\n",
        "axes[0][1].plot(GCN_scores['test_accuracy'], c = 'g', linestyle = 'solid', linewidth = 3)\n",
        "\n",
        "axes[0][1].set_ylim(0,1)\n",
        "\n",
        "axes[0][1].set_title(\"Accuracy\")\n",
        "axes[0][1].set_xlabel('Epoch', fontsize = 15)\n",
        "axes[0][1].set_ylabel('score', fontsize = 15)\n",
        "\n",
        "axes[0][1].tick_params(labelsize = 15)\n",
        "axes[0][1].grid()\n",
        "\n",
        "axes[0][1].legend(['Train Accuracy', 'Val Accuracy', 'Test Accuracy'], fontsize = 15)\n",
        "\n",
        "\n",
        "# office 31 loss\n",
        "axes[1][0].plot(GCN_losses, c = 'r', linestyle = 'solid', linewidth = 3)\n",
        "\n",
        "axes[1][0].set_ylim(0,3)\n",
        "\n",
        "axes[1][0].set_title(\"Train Loss\")\n",
        "axes[1][0].set_xlabel('Epoch', fontsize = 15)\n",
        "axes[1][0].set_ylabel('loss', fontsize = 15)\n",
        "\n",
        "axes[1][0].tick_params(labelsize = 15)\n",
        "axes[1][0].grid()\n",
        "\n",
        "axes[1][0].legend(['Train loss'], fontsize = 15)\n",
        "\n",
        "\n",
        "# plot\n",
        "plt.xticks(fontsize = '20')\n",
        "plt.yticks(fontsize = '20')\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "_4V1qAmTsphA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment with Grid search\n",
        "\n",
        "def grid_search(data, model, model_params, EPOCH, learning_rate):\n",
        "\n",
        "  model = model(**model_params)\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  losses = []\n",
        "  scores = defaultdict(list)\n",
        "\n",
        "  for epoch in range(1, EPOCHS):\n",
        "\n",
        "    loss = trainer(data, model, optimizer, criterion, 2)\n",
        "    \n",
        "    train_score = tester(data, model, data['train_mask'][:,4], model_params['nClasses'])\n",
        "    val_score = tester(data, model, data['val_mask'][:,4], model_params['nClasses'])\n",
        "    test_score = tester(data, model, data['test_mask'], model_params['nClasses'])\n",
        "\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    scores['train_auc'].append(train_score[0])\n",
        "    scores['val_auc'].append(val_score[0])\n",
        "    scores['test_auc'].append(test_score[0])\n",
        "\n",
        "    scores['train_accuracy'].append(train_score[1])\n",
        "    scores['val_accuracy'].append(val_score[1])\n",
        "    scores['test_accuracy'].append(test_score[1])\n",
        "\n",
        "    if epoch % 100 == 0 :\n",
        "      print('epoch : {}, train loss : {}'.format(epoch, loss))\n",
        "\n",
        "\n",
        "  return model, losses, scores\n"
      ],
      "metadata": {
        "id": "e4ucLZA34wBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from itertools import product\n",
        "\n",
        "learning_rates = [0.1, 0.01, 0.001]\n",
        "hidden_channels = [10, 20, 30]\n",
        "dropout_rates = [0.2, 0.4, 0.6]\n",
        "\n",
        "i = 0\n",
        "for hc, lr, dp in product(hidden_channels, learning_rates, dropout_rates):\n",
        "\n",
        "  print('hidden channerls : {}, learning rates : {}, dropout_rates : {}'.format(hc, lr, dp))\n",
        "\n",
        "  params = {\n",
        "      \"data\" : data,\n",
        "      \"model\" : GAT,\n",
        "      \"model_params\" : {\n",
        "          \"hidden_channels\" : hc,\n",
        "          \"nFeatures\" : wikics_dataset.num_features,\n",
        "          \"nClasses\" : wikics_dataset.num_classes,\n",
        "          \"dropout_rate\" : dp\n",
        "\n",
        "      },\n",
        "      \"EPOCH\" : 1000,\n",
        "      \"learning_rate\" : lr\n",
        "  }\n",
        "\n",
        "  model, losses, scores = grid_search(**params)\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "OTdV7tuYr_gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(2,2, figsize = (16,16))\n",
        "\n",
        "# AUC\n",
        "axes[0][0].plot(scores['train_auc'], c = 'r', linestyle = 'solid', linewidth = 3)\n",
        "axes[0][0].plot(scores['val_auc'], c = 'b', linestyle = 'solid', linewidth = 3)\n",
        "axes[0][0].plot(scores['test_auc'], c = 'g', linestyle = 'solid', linewidth = 3)\n",
        "\n",
        "axes[0][0].set_ylim(0,1)\n",
        "\n",
        "axes[0][0].set_title(\"AUC\")\n",
        "axes[0][0].set_xlabel('Epoch', fontsize = 15)\n",
        "axes[0][0].set_ylabel('Score', fontsize = 15)\n",
        "\n",
        "axes[0][0].tick_params(labelsize = 15)\n",
        "axes[0][0].grid()\n",
        "\n",
        "axes[0][0].legend(['Train AUC', 'Val AUC', 'Test AUC'], fontsize = 15)\n",
        "\n",
        "\n",
        "# Accuracy\n",
        "axes[0][1].plot(scores['train_accuracy'], c = 'r', linestyle = 'solid', linewidth = 3)\n",
        "axes[0][1].plot(scores['val_accuracy'], c = 'b', linestyle = 'solid', linewidth = 3)\n",
        "axes[0][1].plot(scores['test_accuracy'], c = 'g', linestyle = 'solid', linewidth = 3)\n",
        "\n",
        "axes[0][1].set_ylim(0,1)\n",
        "\n",
        "axes[0][1].set_title(\"Accuracy\")\n",
        "axes[0][1].set_xlabel('Epoch', fontsize = 15)\n",
        "axes[0][1].set_ylabel('score', fontsize = 15)\n",
        "\n",
        "axes[0][1].tick_params(labelsize = 15)\n",
        "axes[0][1].grid()\n",
        "\n",
        "axes[0][1].legend(['Train Accuracy', 'Val Accuracy', 'Test Accuracy'], fontsize = 15)\n",
        "\n",
        "\n",
        "# office 31 loss\n",
        "axes[1][0].plot(losses, c = 'r', linestyle = 'solid', linewidth = 3)\n",
        "\n",
        "axes[1][0].set_ylim(0,3)\n",
        "\n",
        "axes[1][0].set_title(\"Train Loss\")\n",
        "axes[1][0].set_xlabel('Epoch', fontsize = 15)\n",
        "axes[1][0].set_ylabel('loss', fontsize = 15)\n",
        "\n",
        "axes[1][0].tick_params(labelsize = 15)\n",
        "axes[1][0].grid()\n",
        "\n",
        "axes[1][0].legend(['Train loss'], fontsize = 15)\n",
        "\n",
        "\n",
        "# plot\n",
        "plt.xticks(fontsize = '20')\n",
        "plt.yticks(fontsize = '20')\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "YQ5Rbd4Gh3n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B_Pl-HnznYok"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}